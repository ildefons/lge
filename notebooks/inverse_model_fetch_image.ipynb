{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse model on FetchNoTask\n",
    "\n",
    "## Instanciate and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_robotics\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecTransposeImage\n",
    "\n",
    "env = VecTransposeImage(\n",
    "    make_vec_env(\n",
    "        \"__root__/FetchNoTask-v1\",\n",
    "        env_kwargs=dict(image_obs_space=True),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initilize the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a buffer and feed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def collect_rollouts(n, env, replay_buffer):\n",
    "    num_timesteps = 0\n",
    "    last_obs = env.reset()\n",
    "\n",
    "    while num_timesteps < n:\n",
    "        # Select action randomly or according to policy\n",
    "        actions = np.array([env.action_space.sample()])\n",
    "\n",
    "        # Rescale and perform action\n",
    "        new_obs, rewards, dones, infos = env.step(actions)\n",
    "\n",
    "        num_timesteps += env.num_envs\n",
    "        # Avoid modification by reference\n",
    "        next_obs = deepcopy(new_obs)\n",
    "\n",
    "        # As the VecEnv resets automatically, new_obs is already the\n",
    "        # first observation of the next episode\n",
    "        for i, done in enumerate(dones):\n",
    "            if done and infos[i].get(\"terminal_observation\") is not None:\n",
    "                next_obs[i] = infos[i][\"terminal_observation\"]\n",
    "\n",
    "        replay_buffer.add(\n",
    "            last_obs,\n",
    "            next_obs,\n",
    "            actions,\n",
    "            rewards,\n",
    "            dones,\n",
    "            infos,\n",
    "        )\n",
    "\n",
    "        last_obs = new_obs\n",
    "\n",
    "\n",
    "train_buffer = ReplayBuffer(\n",
    "    10_000,\n",
    "    env.observation_space,\n",
    "    env.action_space,\n",
    "    device=device,\n",
    ")\n",
    "test_buffer = ReplayBuffer(\n",
    "    1_000,\n",
    "    env.observation_space,\n",
    "    env.action_space,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "collect_rollouts(10_000, env, train_buffer)\n",
    "collect_rollouts(1_000, env, test_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_buffer.pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciate the model and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lge.inverse_model import ConvInverseModel\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "inverse_model = ConvInverseModel(action_size=env.action_space.shape[0], latent_size=64).to(device)\n",
    "optimizer = optim.Adam(inverse_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:     0\tprediction loss: train 0.28007, test: 0.37901 \n",
      "epoch:   100\tprediction loss: train 0.32289, test: 0.32507 \n",
      "epoch:   200\tprediction loss: train 0.29163, test: 0.38265 \n",
      "epoch:   300\tprediction loss: train 0.31497, test: 0.33771 \n",
      "epoch:   400\tprediction loss: train 0.25974, test: 0.24013 \n",
      "epoch:   500\tprediction loss: train 0.20154, test: 0.18621 \n",
      "epoch:   600\tprediction loss: train 0.18039, test: 0.15986 \n",
      "epoch:   700\tprediction loss: train 0.19056, test: 0.18834 \n",
      "epoch:   800\tprediction loss: train 0.17010, test: 0.18471 \n",
      "epoch:   900\tprediction loss: train 0.19071, test: 0.16275 \n",
      "epoch:  1000\tprediction loss: train 0.16842, test: 0.15825 \n",
      "epoch:  1100\tprediction loss: train 0.15867, test: 0.20894 \n",
      "epoch:  1200\tprediction loss: train 0.18944, test: 0.17452 \n",
      "epoch:  1300\tprediction loss: train 0.19739, test: 0.17596 \n",
      "epoch:  1400\tprediction loss: train 0.17995, test: 0.20506 \n",
      "epoch:  1500\tprediction loss: train 0.14707, test: 0.21014 \n",
      "epoch:  1600\tprediction loss: train 0.19561, test: 0.16469 \n",
      "epoch:  1700\tprediction loss: train 0.15679, test: 0.17095 \n",
      "epoch:  1800\tprediction loss: train 0.16387, test: 0.15712 \n",
      "epoch:  1900\tprediction loss: train 0.16414, test: 0.19306 \n",
      "epoch:  2000\tprediction loss: train 0.15719, test: 0.18004 \n",
      "epoch:  2100\tprediction loss: train 0.19660, test: 0.16755 \n",
      "epoch:  2200\tprediction loss: train 0.18292, test: 0.18672 \n",
      "epoch:  2300\tprediction loss: train 0.17287, test: 0.14893 \n",
      "epoch:  2400\tprediction loss: train 0.17287, test: 0.17099 \n",
      "epoch:  2500\tprediction loss: train 0.16890, test: 0.18955 \n",
      "epoch:  2600\tprediction loss: train 0.15524, test: 0.13792 \n",
      "epoch:  2700\tprediction loss: train 0.13115, test: 0.17858 \n",
      "epoch:  2800\tprediction loss: train 0.11818, test: 0.10876 \n",
      "epoch:  2900\tprediction loss: train 0.14647, test: 0.12106 \n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "for epoch in range(3_000):\n",
    "    # Sample\n",
    "    sample = train_buffer.sample(32)\n",
    "    observations = sample.observations.float() / 255\n",
    "    next_observations = sample.next_observations.float() / 255\n",
    "    actions = sample.actions\n",
    "\n",
    "    # Compute the output image\n",
    "    inverse_model.train()\n",
    "    pred_actions = inverse_model(observations, next_observations)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = F.mse_loss(pred_actions, actions)\n",
    "\n",
    "    # Step the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        sample = test_buffer.sample(32)\n",
    "        observations = sample.observations.float() / 255\n",
    "        next_observations = sample.next_observations.float() / 255\n",
    "        actions = sample.actions\n",
    "\n",
    "        # Compute the output image\n",
    "        inverse_model.eval()\n",
    "        pred_actions = inverse_model(observations, next_observations)\n",
    "        # Compute the loss\n",
    "        test_loss = F.mse_loss(pred_actions, actions)\n",
    "        print(\"epoch: {:5d}\\tprediction loss: train {:.5f}, test: {:.5f} \".format(epoch, loss.item(), test_loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the result for one transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true action\t\t [-0.65865135 -0.61914843 -0.21977454 -0.4925384 ]\n",
      "predicted action\t [-0.46685636 -0.5837856  -0.22674772 -0.00502674]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=168x84>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# Sample one transition\n",
    "sample = test_buffer.sample(1)\n",
    "observations = sample.observations.float() / 255\n",
    "next_observations = sample.next_observations.float() / 255\n",
    "actions = sample.actions\n",
    "\n",
    "# Predict the action\n",
    "inverse_model.eval()\n",
    "pred_actions = inverse_model(observations, next_observations)\n",
    "\n",
    "# See the result\n",
    "print(\"true action\\t\\t\", actions.squeeze().detach().cpu().numpy())\n",
    "print(\"predicted action\\t\", pred_actions.squeeze().detach().cpu().numpy())\n",
    "\n",
    "\n",
    "observation = sample.observations.squeeze().moveaxis(0, 2).detach().cpu().numpy()\n",
    "next_observation = sample.next_observations.squeeze().moveaxis(0, 2).detach().cpu().numpy()\n",
    "img = np.hstack((observation, next_observation))\n",
    "img = Image.fromarray(img)\n",
    "display(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f48e9823b73d61fb1e9f2e586933b91323c7e489dd89b69b8ad5cbedc4bff826"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
