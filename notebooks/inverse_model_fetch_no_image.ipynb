{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse model on FetchNoTask\n",
    "\n",
    "## Instanciate and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_robotics\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecTransposeImage\n",
    "\n",
    "n_envs = 8\n",
    "\n",
    "env =make_vec_env(\n",
    "        \"__root__/FetchNoTask-v1\",\n",
    "        n_envs=n_envs,\n",
    "        env_kwargs=dict(image_obs_space=False),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initilize the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a buffer and feed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def collect_rollouts(n, env, replay_buffer):\n",
    "    num_timesteps = 0\n",
    "    last_obs = env.reset()\n",
    "\n",
    "    while num_timesteps < n:\n",
    "        # Select action randomly or according to policy\n",
    "        action = np.array([env.action_space.sample() for _ in range(env.num_envs)])\n",
    "\n",
    "        # Rescale and perform action\n",
    "        new_obs, rewards, dones, infos = env.step(action)\n",
    "\n",
    "        num_timesteps += env.num_envs\n",
    "        # Avoid modification by reference\n",
    "        next_obs = deepcopy(new_obs)\n",
    "\n",
    "        # As the VecEnv resets automatically, new_obs is already the\n",
    "        # first observation of the next episode\n",
    "        for i, done in enumerate(dones):\n",
    "            if done and infos[i].get(\"terminal_observation\") is not None:\n",
    "                next_obs[i] = infos[i][\"terminal_observation\"]\n",
    "\n",
    "        replay_buffer.add(\n",
    "            last_obs,\n",
    "            next_obs,\n",
    "            action,\n",
    "            rewards,\n",
    "            dones,\n",
    "            infos,\n",
    "        )\n",
    "\n",
    "        last_obs = new_obs\n",
    "\n",
    "\n",
    "train_buffer = ReplayBuffer(\n",
    "    10_000,\n",
    "    env.observation_space,\n",
    "    env.action_space,\n",
    "    n_envs=n_envs,\n",
    "    device=device,\n",
    ")\n",
    "test_buffer = ReplayBuffer(\n",
    "    1_000,\n",
    "    env.observation_space,\n",
    "    env.action_space,\n",
    "    n_envs=n_envs,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "collect_rollouts(10_000, env, train_buffer)\n",
    "collect_rollouts(1_000, env, test_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciate the model and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lge.inverse_model import LinearInverseModel\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "inverse_model = LinearInverseModel(obs_size=env.observation_space.shape[0], action_size=env.action_space.shape[0], latent_size=16).to(device)\n",
    "optimizer = optim.Adam(inverse_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:     0\tprediction loss: train 0.36344, test: 0.31484 \n",
      "epoch:   100\tprediction loss: train 0.34127, test: 0.33228 \n",
      "epoch:   200\tprediction loss: train 0.35044, test: 0.31731 \n",
      "epoch:   300\tprediction loss: train 0.36411, test: 0.33084 \n",
      "epoch:   400\tprediction loss: train 0.32048, test: 0.31557 \n",
      "epoch:   500\tprediction loss: train 0.33997, test: 0.31311 \n",
      "epoch:   600\tprediction loss: train 0.32696, test: 0.31758 \n",
      "epoch:   700\tprediction loss: train 0.30179, test: 0.28957 \n",
      "epoch:   800\tprediction loss: train 0.27369, test: 0.24094 \n",
      "epoch:   900\tprediction loss: train 0.22831, test: 0.19520 \n",
      "epoch:  1000\tprediction loss: train 0.25117, test: 0.19578 \n",
      "epoch:  1100\tprediction loss: train 0.24141, test: 0.19008 \n",
      "epoch:  1200\tprediction loss: train 0.21563, test: 0.18296 \n",
      "epoch:  1300\tprediction loss: train 0.21224, test: 0.18053 \n",
      "epoch:  1400\tprediction loss: train 0.23942, test: 0.17828 \n",
      "epoch:  1500\tprediction loss: train 0.20874, test: 0.15739 \n",
      "epoch:  1600\tprediction loss: train 0.20994, test: 0.14648 \n",
      "epoch:  1700\tprediction loss: train 0.18738, test: 0.16560 \n",
      "epoch:  1800\tprediction loss: train 0.19104, test: 0.13479 \n",
      "epoch:  1900\tprediction loss: train 0.16529, test: 0.12685 \n",
      "epoch:  2000\tprediction loss: train 0.17963, test: 0.12205 \n",
      "epoch:  2100\tprediction loss: train 0.16997, test: 0.12152 \n",
      "epoch:  2200\tprediction loss: train 0.17157, test: 0.11493 \n",
      "epoch:  2300\tprediction loss: train 0.16634, test: 0.11048 \n",
      "epoch:  2400\tprediction loss: train 0.15197, test: 0.10657 \n",
      "epoch:  2500\tprediction loss: train 0.17896, test: 0.11173 \n",
      "epoch:  2600\tprediction loss: train 0.16046, test: 0.10464 \n",
      "epoch:  2700\tprediction loss: train 0.16880, test: 0.11202 \n",
      "epoch:  2800\tprediction loss: train 0.16928, test: 0.11440 \n",
      "epoch:  2900\tprediction loss: train 0.16141, test: 0.11092 \n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "for epoch in range(3_000):\n",
    "    # Sample\n",
    "    sample = train_buffer.sample(128)\n",
    "    observations = sample.observations.float()\n",
    "    next_observations = sample.next_observations.float()\n",
    "    actions = sample.actions\n",
    "\n",
    "    # Compute the output image\n",
    "    inverse_model.train()\n",
    "    pred_actions = inverse_model(observations, next_observations)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = F.mse_loss(pred_actions, actions)\n",
    "\n",
    "    # Step the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        sample = test_buffer.sample(128)\n",
    "        observations = sample.observations.float()\n",
    "        next_observations = sample.next_observations.float()\n",
    "        actions = sample.actions\n",
    "\n",
    "        # Compute the output image\n",
    "        inverse_model.eval()\n",
    "        pred_actions = inverse_model(observations, next_observations)\n",
    "        # Compute the loss\n",
    "        test_loss = F.mse_loss(pred_actions, actions)\n",
    "        print(\"epoch: {:5d}\\tprediction loss: train {:.5f}, test: {:.5f} \".format(epoch, loss.item(), test_loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the result for one transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true action\t\t tensor([[-0.8390,  0.3584, -0.8453, -0.5738]])\n",
      "predicted action\t tensor([[-0.6592,  0.2004, -0.5361, -0.0446]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Sample one transition\n",
    "sample = test_buffer.sample(1)\n",
    "observations = sample.observations.float()\n",
    "next_observations = sample.next_observations.float()\n",
    "actions = sample.actions\n",
    "\n",
    "# Predict the action\n",
    "inverse_model.eval()\n",
    "pred_actions = inverse_model(observations, next_observations)\n",
    "\n",
    "# See the result\n",
    "print(\"true action\\t\\t\", actions)\n",
    "print(\"predicted action\\t\", pred_actions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b39a0bc9b5701310f2a160ed7999133b9f255677497bcb14f5070dce9169775"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
