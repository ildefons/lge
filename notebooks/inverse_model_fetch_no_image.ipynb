{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse model on FetchNoTask\n",
    "\n",
    "## Instanciate and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_robotics\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "env = make_vec_env(\n",
    "    \"__root__/FetchNoTask-v1\",\n",
    "    env_kwargs=dict(image_obs_space=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initilize the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a buffer and feed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3.common.buffers import ReplayBuffer\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def collect_rollouts(n, env, replay_buffer):\n",
    "    num_timesteps = 0\n",
    "    last_obs = env.reset()\n",
    "\n",
    "    while num_timesteps < n:\n",
    "        # Select action randomly or according to policy\n",
    "        action = np.array([env.action_space.sample()])\n",
    "\n",
    "        # Rescale and perform action\n",
    "        new_obs, rewards, dones, infos = env.step(action)\n",
    "\n",
    "        num_timesteps += env.num_envs\n",
    "        # Avoid modification by reference\n",
    "        next_obs = deepcopy(new_obs)\n",
    "\n",
    "        # As the VecEnv resets automatically, new_obs is already the\n",
    "        # first observation of the next episode\n",
    "        for i, done in enumerate(dones):\n",
    "            if done and infos[i].get(\"terminal_observation\") is not None:\n",
    "                next_obs[i] = infos[i][\"terminal_observation\"]\n",
    "\n",
    "        replay_buffer.add(\n",
    "            last_obs,\n",
    "            next_obs,\n",
    "            action,\n",
    "            rewards,\n",
    "            dones,\n",
    "            infos,\n",
    "        )\n",
    "\n",
    "        last_obs = new_obs\n",
    "\n",
    "\n",
    "train_buffer = ReplayBuffer(\n",
    "    10_000,\n",
    "    env.observation_space,\n",
    "    env.action_space,\n",
    "    device=device,\n",
    ")\n",
    "test_buffer = ReplayBuffer(\n",
    "    1_000,\n",
    "    env.observation_space,\n",
    "    env.action_space,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "collect_rollouts(10_000, env, train_buffer)\n",
    "collect_rollouts(1_000, env, test_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciate the model and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lge.inverse_model import LinearInverseModel\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "inverse_model = LinearInverseModel(\n",
    "    obs_size=env.observation_space.shape[0], action_size=env.action_space.shape[0], latent_size=64\n",
    ").to(device)\n",
    "optimizer = optim.Adam(inverse_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:     0\tprediction loss: train 0.36175, test: 0.34301 \n",
      "epoch:   100\tprediction loss: train 0.33805, test: 0.32752 \n",
      "epoch:   200\tprediction loss: train 0.32568, test: 0.33114 \n",
      "epoch:   300\tprediction loss: train 0.33064, test: 0.35653 \n",
      "epoch:   400\tprediction loss: train 0.31974, test: 0.34449 \n",
      "epoch:   500\tprediction loss: train 0.31977, test: 0.33699 \n",
      "epoch:   600\tprediction loss: train 0.32486, test: 0.31881 \n",
      "epoch:   700\tprediction loss: train 0.32025, test: 0.30193 \n",
      "epoch:   800\tprediction loss: train 0.29274, test: 0.27968 \n",
      "epoch:   900\tprediction loss: train 0.28354, test: 0.28798 \n",
      "epoch:  1000\tprediction loss: train 0.27696, test: 0.28562 \n",
      "epoch:  1100\tprediction loss: train 0.25680, test: 0.26894 \n",
      "epoch:  1200\tprediction loss: train 0.23860, test: 0.22877 \n",
      "epoch:  1300\tprediction loss: train 0.22639, test: 0.21489 \n",
      "epoch:  1400\tprediction loss: train 0.20641, test: 0.22778 \n",
      "epoch:  1500\tprediction loss: train 0.20833, test: 0.22224 \n",
      "epoch:  1600\tprediction loss: train 0.23400, test: 0.22241 \n",
      "epoch:  1700\tprediction loss: train 0.22583, test: 0.20249 \n",
      "epoch:  1800\tprediction loss: train 0.20933, test: 0.20691 \n",
      "epoch:  1900\tprediction loss: train 0.19331, test: 0.17551 \n",
      "epoch:  2000\tprediction loss: train 0.17917, test: 0.16173 \n",
      "epoch:  2100\tprediction loss: train 0.17166, test: 0.14152 \n",
      "epoch:  2200\tprediction loss: train 0.17902, test: 0.14908 \n",
      "epoch:  2300\tprediction loss: train 0.15785, test: 0.13364 \n",
      "epoch:  2400\tprediction loss: train 0.17092, test: 0.13092 \n",
      "epoch:  2500\tprediction loss: train 0.17659, test: 0.13027 \n",
      "epoch:  2600\tprediction loss: train 0.17862, test: 0.14162 \n",
      "epoch:  2700\tprediction loss: train 0.15258, test: 0.13031 \n",
      "epoch:  2800\tprediction loss: train 0.16424, test: 0.12923 \n",
      "epoch:  2900\tprediction loss: train 0.16318, test: 0.12455 \n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "for epoch in range(3_000):\n",
    "    # Sample\n",
    "    sample = train_buffer.sample(128)\n",
    "    observations = sample.observations.float()\n",
    "    next_observations = sample.next_observations.float()\n",
    "    actions = sample.actions\n",
    "\n",
    "    # Compute the output image\n",
    "    inverse_model.train()\n",
    "    pred_actions = inverse_model(observations, next_observations)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = F.mse_loss(pred_actions, actions)\n",
    "\n",
    "    # Step the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        sample = test_buffer.sample(128)\n",
    "        observations = sample.observations.float()\n",
    "        next_observations = sample.next_observations.float()\n",
    "        actions = sample.actions\n",
    "\n",
    "        # Compute the output image\n",
    "        inverse_model.eval()\n",
    "        pred_actions = inverse_model(observations, next_observations)\n",
    "        # Compute the loss\n",
    "        test_loss = F.mse_loss(pred_actions, actions)\n",
    "        print(\"epoch: {:5d}\\tprediction loss: train {:.5f}, test: {:.5f} \".format(epoch, loss.item(), test_loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the result for one transition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true action\t\t [ 0.5259334  -0.46869573  0.0570057   0.58459854]\n",
      "predicted action\t [ 0.43617848 -0.15052563  0.06971782 -0.01091865]\n"
     ]
    }
   ],
   "source": [
    "# Sample one transition\n",
    "sample = test_buffer.sample(1)\n",
    "observations = sample.observations.float()\n",
    "next_observations = sample.next_observations.float()\n",
    "actions = sample.actions\n",
    "\n",
    "# Predict the action\n",
    "inverse_model.eval()\n",
    "pred_actions = inverse_model(observations, next_observations)\n",
    "\n",
    "# See the result\n",
    "print(\"true action\\t\\t\", actions.squeeze().detach().cpu().numpy())\n",
    "print(\"predicted action\\t\", pred_actions.squeeze().detach().cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f48e9823b73d61fb1e9f2e586933b91323c7e489dd89b69b8ad5cbedc4bff826"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
